import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import math
import json
import re
import math
import seaborn as sns
import scipy.stats as stats
from sklearn.model_selection import train_test_split
from sklearn.model_selection import RandomizedSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import RobustScaler
from sklearn.preprocessing import MinMaxScaler
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LogisticRegression
get_ipython().run_line_magic("matplotlib", " inline")

# Gaather Data#
# read in the json files
portfolio = pd.read_json('data/portfolio.json', orient='records', lines=True)
profile = pd.read_json('data/profile.json', orient='records', lines=True)
transcript = pd.read_json('data/transcript.json', orient='records', lines=True)


profile.head()


profile.describe()


profile.duplicated().sum()


transcript.head()


def create_user_id_map(data=profile):
    """
    Create a map for hashed 'person' in profile to simplify the data
    Parameters
    -------
    data : the profile dataframe
    Returns
    ---------
    user_id_map: The map DataFrame between hashed person informations and
    interger numbers
    """
    user_id_map = pd.DataFrame(
        {'person': data['id'],
         'person_id': range(len(data['id']))}
    )
    return user_id_map


user_id_map = create_user_id_map()


def clean_profile_(data=profile, user_id_map=user_id_map):
    """
    Clean the profile dataframe.
    1. if the ages are above 117, treat this as Nan
    2. replace hashed 'person' into 'person_id'
    Parameters
    ------
    data : The profile dataframe.
    user_id_map : The dataframe contains the relations between hashed 'person' and 'person_id'
    Returns
    -------
    profile_new : The cleaned version of profile
    """
    profile_new = data.merge(user_id_map, how='left', left_on='id', right_on='person')
    profile_new.drop(['id', 'person'], axis=1, inplace=True)
    profile_new.loc[profile_new['age'] >= 117, 'age'] = np.nan
    # profile_new['income']  = np.log10(profile_new['income'])
    return profile_new


clean_profile = clean_profile_()
clean_profile.head()


portfolio


# map dict for hashed offer id 
map_dict = {'offer_id': ['BOGO_r10_d10_u7',
                         'BOGO_r10_d10_u5',
                         'INFO_u4',
                         'BOGO_r5_d5_u7',
                         'DIS_r5_d20_u10',
                         'DIS_r3_d7_u7',
                         'DIS_r2_d10_u10',
                         'INFO_u3',
                         'BOGO_r5_d5_u5',
                         'DIS_r2_d10_u7']}
offer_id_map = pd.DataFrame(map_dict)
offer_id_map = offer_id_map.merge(portfolio.loc[:, 'id'], left_index=True, right_index=True)
offer_id_map.rename(columns={'id': 'portfolio_id'}, inplace=True)
offer_id_map


def clean_portfolio(portfolio=portfolio, offer_id_map=offer_id_map):
    """
    clean the portfolio data, change hashed "ID" into "offer_id" according to offer_id_map
    split channels into columns
    Parameters
    -----
    portfolio : The original profile dataframe
    offer_id_map : The dataFrame map between hased 'id' and more readable 'offer_id'.
    Returns
    -----
    port_clean : the cleaned version of profile
    """
    port_clean = portfolio.copy()
    channel_list = []
    for channel in portfolio['channels']:
        channel_list.extend(channel)
    channel_set = set(channel_lis 
    # convert channels into dummies
    for channel in channel_set:
        port_clean['channel_' + channel] = port_clean['channels'].apply(lambda x: x.count(channel)>0)
        
    # change id according to offer_id_map
    
    port_clean = port_clean.merge(offer_id_map, left_on= 'id', right_on = 'portfolio_id')
        
    
    port_clean.drop(['channels','id', 'portfolio_id'], axis = 1, inplace = True)
    return port_clean


portfolio_clean = clean_portfolio()


portfolio_clean


# Clean ###
def elementary_transcript(transcript = transcript, portfolio = portfolio_clean, offer_id_map = offer_id_map, user_id_map = user_id_map):
    """
    clean the transcript data, use person_id, offer_id instead of hash number.
    Parameters
    ------------
    transcript : The transcript DataFrame
    portfolio : The cleaned portfolio DataFrame
    offer_id_map : The offer id map dataFrame
    user_id_map : The user id map dataFrame
    Returns
    ------------
    transcript_clean : The elementary cleaned transcript DataFrame
    """
    
    # simplify person to person_id
    transcript_clean = transcript.copy()    

    transcript_clean = transcript_clean.merge(user_id_map, on = 'person')    
    print(transcript_clean.event.unique())
    # 
    
    transcript_clean['portfolio_id'] = transcript_clean['value'].apply(
        lambda x : x.get('offer_id', np.nan) if (x.get('offer id', np.nan) is np.nan) else x.get('offer id', np.nan)
    )


    transcript_clean['amount'] = transcript_clean['value'].apply(lambda x :x.get('amount', np.nan))

    transcript_clean['reward'] = transcript_clean['value'].apply(lambda x :x.get('reward', np.nan))
    transcript_clean = transcript_clean.merge(offer_id_map,how = 'left', on = 'portfolio_id')
#    transcript_clean['offer_id'] = transcript_clean['offer_id'].astype('Int64')
    transcript_clean.drop(['person','value', 'portfolio_id'], axis = 1, inplace = True)

    return transcript_clean

elementary_trans = elementary_transcript()
elementary_trans.head()


### Visualize ###
## plot the histogram of age , income
fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18,6))
sns.histplot(clean_profile, x = 'age', hue = 'gender', ax = ax1, multiple = 'stack' ,bins = range(0, 120, 10))
ax1.set_title('Histogram of Age by "Gender"')
ax1.set_xlabel('Age')

sns.histplot(clean_profile, x = 'income', hue = 'gender', ax = ax2, multiple = 'stack' ,bins = 10)
ax2.set_title('Histogram of Income by "Gender"')
ax2.set_xlabel('Income')

sns.histplot(clean_profile, x = 'gender', ax = ax3)
ax3.set_title('Histogram of Gender')
ax3.set_xlabel('Gender')
plt.show()


### Clean ###
def trans_reward_(transcript=elementary_trans):
    """
    summary the transcript for each transaction. Find out the offer useage and reward for each transaction.
    Parameters
    ----------
    transcript = the Dataframe of transcript after elementary clean
    Returns
    ----------
    trans_reward : The dataframe of the summary of transcript with reward informations.
    """
    
    sum_reward = elementary_trans[elementary_trans['event'] == 'offer completed'].groupby(['person_id', 'time']).sum()['reward'].reset_index()

    count_complete_offer = elementary_trans[elementary_trans['event'] == 'offer completed'].groupby(['person_id', 'time','offer_id']).count()['reward'].unstack()
    count_complete_offer['offer_used'] = count_complete_offer.sum(axis = 1)
    trans = elementary_trans[elementary_trans['event'] == 'transaction']
    trans = trans.drop(['reward', 'offer_id'], axis = 1)

    trans_reward = trans.merge(sum_reward, on = ['person_id','time'], how = 'left')
    trans_reward = trans_reward.merge(count_complete_offer, on = ['person_id','time'], how = 'left')
    trans_reward['bogo'] = trans_reward.filter(regex = '^BOGO', axis = 1).any(axis = 1)
    trans_reward['discount'] = trans_reward.filter(regex = '^DIS', axis = 1).any(axis = 1)

    return trans_reward


trans_reward = trans_reward_()
trans_reward.head()


#find out are there transactions use both BOGO and DISCOUNT.
bogo_discount = trans_reward['bogo'] & trans_reward['discount']
print('About {}% of the transactions use both BOGO and DISCOUNT. '.format(round(bogo_discount.mean()*100)))


# For better analysis and model we remove the infos which use both BOGO and DISCOUNT
trans_reward = trans_reward[~bogo_discount]


fig, (ax1, ax2) = plt.subplots(nrows = 1, ncols = 2, figsize = (12,6))

sns.histplot(trans_reward, x = 'amount', bins = 50, ax = ax1, stat = 'percent')
ax1.set_title('Histogram of the Price of each order')
ax1.set_xlabel('Price of each order')

sns.histplot(trans_reward, x = 'reward', bins = 20, ax = ax2, stat = 'percent')
ax2.set_title('Histogram of Reward of each order')

plt.show()


fig, (ax1, ax2) = plt.subplots(nrows = 1, ncols = 2, figsize = (12,6))


sns.histplot(trans_reward, x = 'amount', bins = range(0,60,5), ax = ax1, stat = 'percent')
ax1.set_title('Histogram of the Price of each order(<100)')
ax1.set_xlabel('Price of each order')

sns.histplot(trans_reward, x = 'offer_used', ax = ax2, stat = 'percent')
ax2.set_title('Histogram of the Offer Used per Order')
ax2.set_xlabel('Offer Used per Order')

plt.show()


### Assess ###
### T test ###
def ttest_user(without_offer, with_offer):

    if (len(with_offer) > 1) and (len(without_offer) > 1):
        pvalue = stats.ttest_ind(without_offer, with_offer)[1]
    elif (len(with_offer) > 0) and (len(without_offer) > 1):
        pvalue = stats.ttest_1samp(a=without_offer, popmean = with_offer, alternative = 'two-sided')[1][0]
    else:
        pvalue = np.nan
    return pvalue


def ttest_offer(data=trans_reward):
    pvalue_df = pd.DataFrame(columns = ['person_id', 'pvalue'])
    user_set = data['person_id'].unique()
    for user in user_set:
        user_data = data[data['person_id'] == user ]
        reward_isnan = user_data['reward'].isnull()

        if sum(reward_isnan) > 0:
            without_offer = user_data[reward_isnan]['amount'].to_numpy()

        else:
            without_offer = np.array([])
        if sum(~reward_isnan) > 0:
            with_offer = user_data[~reward_isnan][['amount', 'reward']].sum(axis = 1).to_numpy()
            
        else:
            with_offer = np.array([])

        pvalue = ttest_user(without_offer, with_offer)
        pvalue_df = pvalue_df.append({'person_id': user,'pvalue':pvalue}, ignore_index = True)

    return pvalue_df

discount_pvalue_df = ttest_offer(trans_reward[~trans_reward['bogo']])
bogo_pvalue_df = ttest_offer(trans_reward[~trans_reward['discount']])


trans_reward.head()


### Assess ###
### T test ###
def ttest_user(without_offer, with_offer):

    if (len(with_offer) > 1) and (len(without_offer) > 1):
        pvalue = stats.ttest_ind(without_offer, with_offer)[1]
    elif (len(with_offer) > 0) and (len(without_offer) > 1):
        pvalue = stats.ttest_1samp(a=without_offer, popmean = with_offer, alternative = 'two-sided')[1][0]
    else:
        pvalue = np.nan
    return pvalue


def ttest_offer(data = trans_reward, gross_profit = 0.4):
    pvalue_df = pd.DataFrame(columns = ['person_id', 'pvalue'])
    data.loc[:, 'amount_profit'] = data['amount']* gross_profit
    data.loc[:, 'reward_cost'] = data['reward'] * ( gross_profit - 1)
    user_set = data['person_id'].unique()
    for user in user_set:
        user_data = data[data['person_id'] == user ].copy()
        reward_isnan = user_data['reward'].isnull()

        if sum(reward_isnan) > 0:
            without_offer = user_data[reward_isnan]['amount_profit'].to_numpy()

        else:
            without_offer = np.array([])
        if sum(~reward_isnan) > 0:
            with_offer = user_data[~reward_isnan][['amount_profit', 'reward_cost']].sum(axis = 1).to_numpy()
            
        else:
            with_offer = np.array([])

        pvalue = ttest_user(without_offer, with_offer)
        pvalue_df = pvalue_df.append({'person_id': user,'pvalue':pvalue}, ignore_index = True)

    return pvalue_df

discount_pvalue_df = ttest_offer(trans_reward[~trans_reward['bogo']])
bogo_pvalue_df = ttest_offer(trans_reward[~trans_reward['discount']])


### Visualize ###
### For T test ###


fig, (ax1, ax2) = plt.subplots(nrows = 1, ncols = 2, figsize = (12, 6))

sns.histplot(data = discount_pvalue_df, x = 'pvalue' , stat = 'percent',bins = 20, ax = ax1)
ax1.axvline(x = 0.05, color = 'r')
ax1.set_xlabel('P value of T test for the comparison of discount useage.')

sns.histplot(data = bogo_pvalue_df, x = 'pvalue', stat = 'percent', bins = 20 ,ax = ax2)
ax2.axvline(x = 0.05, color = 'r')
ax2.set_xlabel('P value of T test for the comparison of BOGO useage.')
plt.show()


def trans_profit(trans_reward = trans_reward, gross_profit = 0.4):
    """
    caculate each transaction profit for modeling
    """
    reward_list = trans_reward['reward'].notnull()
    
    # caculate the mean of the transactions without offer
    mean_trans_without_offer = trans_reward[~reward_list].groupby('person_id').mean()['amount']
   # caculate the mean of the profit without offer
    mean_profit_without_offer = mean_trans_without_offer * gross_profit
    mean_profit_without_offer.rename('mean_profit_without_offer', inplace = True)
    
    trans_with_offer = trans_reward[reward_list].copy()
    trans_with_offer['reward_cost'] = trans_with_offer['reward'] * (1 - gross_profit)

    trans_profit = trans_with_offer.merge(mean_profit_without_offer, on = 'person_id', how = 'left')
    trans_profit['profit'] = trans_profit['amount'] * gross_profit - trans_profit['reward_cost']
    trans_profit['profit_diff'] = trans_profit['profit'] - trans_profit['mean_profit_without_offer']
    return trans_profit

trans_profit = trans_profit()

trans_profit = trans_profit.merge(clean_profile, on = 'person_id', how = 'left')
trans_profit.head()


trans_profit[trans_profit['profit'] < 0]


def mean_amount(trans_reward = trans_reward, gross_profit = 0.4):
    """
    Function to summary the trans_reward dataframe, 
    to get the mean amount and mean amount plus reward for each person for futher model
    
    """
    trans_reward.loc[trans_reward['bogo'],'reward'] *= (1-gross_profit)

    reward_isnan = trans_reward['reward'].isnull()
    amount_reward = trans_reward[~reward_isnan].copy()
    amount_reward['profit'] = amount_reward['amount'] * gross_profit - amount_reward['reward']* (1-gross_profit)
    amount = trans_reward[reward_isnan].copy()
    
    profit_without_offer = amount.groupby('person_id').mean()['amount']* gross_profit
    profit_without_offer = profit_without_offer.reset_index()
    profit_without_offer = profit_without_offer.rename(columns = {'amount':'mean_profit_without_offer'})
    
    count_without_offer = amount.groupby('person_id').count()['amount'].reset_index()
    count_without_offer = count_without_offer.rename(columns = {'amount':'count_without_offer'})
    
    count_offer_total = amount_reward.groupby('person_id').count()['reward'].reset_index()
    count_offer_total = count_offer_total.rename(columns = {'reward':'count_offer'})
    
    offer_sum = amount_reward.groupby('person_id').sum().filter(regex = '^BOGO|DIS', axis = 1)
    profit_with_offer = amount_reward.groupby('person_id').mean()['profit'].reset_index()
    profit_with_offer = profit_with_offer.rename(columns = {'profit':'profit_with_offer'})

    mean_amount = profit_with_offer.merge(profit_without_offer, on = 'person_id', how = 'outer')
    mean_amount = mean_amount.merge(count_without_offer, on = 'person_id', how = 'outer')  
    mean_amount = mean_amount.merge(count_offer_total, on = 'person_id', how = 'outer') 
    mean_amount = mean_amount.merge(offer_sum, on = 'person_id', how = 'left') 
    mean_amount['profit_diff'] = mean_amount['mean_profit_without_offer'] - mean_amount['profit_with_offer']
    
    return mean_amount
    
mean_amount = mean_amount()
mean_amount = mean_amount.merge(clean_profile, on = 'person_id', how = 'left')




mean_amount.describe()


mean_amount['profit_diff'].min()


fig, ((ax0, ax1), (ax2, ax3)) = plt.subplots(nrows = 2, ncols = 2,figsize  = (12,12))
fig.subplots_adjust(left=0.1, right=0.95, bottom=0.15)
sns.histplot(data = mean_amount, x = 'mean_profit_without_offer', bins = range(0, 100, 5),stat = 'percent', hue = 'gender',multiple = 'stack', ax = ax0)
ax0.set_xlabel('The Average Profit per Customer(Without Offer)')
ax0.set_title('Histogram of Averge profit per Customer(Without Offer, Gross Profit Margin = 0.3)')

sns.histplot(data = mean_amount, x = 'profit_with_offer',bins = range(-15, 85,5), stat = 'percent',hue = 'gender',multiple = 'stack', ax = ax1)
ax1.set_xlabel('The Average Profit per Customer(With Offer)')
ax1.set_title('Histogram of Averge Profit per Customer /n (With Offer, Gross Profit Margin = 0.3)')


sns.histplot(data = mean_amount, x= 'count_without_offer',stat = 'percent', hue = 'gender',multiple = 'stack', ax = ax2)
ax2.set_xlabel('The Count of orders without offer')
ax2.set_title('Histogram of The Count of orders without offer')

sns.histplot(data = mean_amount, x = 'count_offer',stat = 'percent', hue = 'gender',multiple = 'stack', ax = ax3)
ax3.set_xlabel('The Count of orders with offer')
ax3.set_title('Histogram of The Count of orders with offer')
plt.show()


fig, ((ax0, ax1), (ax2, ax3)) = plt.subplots(nrows = 2, ncols = 2,figsize  = (12,12))
fig.subplots_adjust(left=0.1, right=0.95, bottom=0.15)
sns.histplot(data = trans_profit, x = 'profit', bins = range(-20, 30, 1),stat = 'percent', hue = 'gender',element = 'poly', ax = ax0)
ax0.set_xlabel('The Profit of each order(With Offer)')
ax0.set_title('Histogram of profit of each order(With Offer, GPM = 0.3)')

sns.histplot(data = trans_profit, x = 'profit_diff',bins = range(-30,30 ,1), stat = 'percent',hue = 'gender',element = 'poly', ax = ax1)
ax1.set_xlabel('The Profit difference from average profit(without offer)')
ax1.set_title('Histogram of Porfit difference (GPM= 0.3)')


sns.histplot(data = trans_profit, x= 'reward_cost',stat = 'percent', hue = 'gender',multiple = 'stack', ax = ax2)
ax2.set_xlabel('The Count of orders without offer')
ax2.set_title('Histogram of The Count of orders without offer')

sns.histplot(data = trans_profit, x = 'amount',stat = 'percent', hue = 'gender',multiple = 'stack', ax = ax3)
ax3.set_xlabel('The Count of orders with offer')
ax3.set_title('Histogram of The Count of orders with offer')
plt.show()


df = mean_amount.drop(['profit_with_offer', 'count_offer', 'became_member_on', 'person_id'], axis = 1)

df = df.dropna(subset = ['profit_diff', 'income', 'age'], axis = 0)
f, ax = plt.subplots(figsize = (12,12))
ax = sns.heatmap(df.corr(), annot = True, fmt = ".2f",square = True)




trans_profit.head()



df_ = trans_profit.drop(['event','amount', 'time', 'reward', 'bogo', 'discount', 'reward_cost', 'profit', 'became_member_on', 'person_id'], axis = 1)

df_ = df_.dropna(subset = ['profit_diff','age','income'], axis = 0)
f, ax = plt.subplots(figsize = (12,12))
ax = sns.heatmap(df_.corr(), annot = True, fmt = ".2f",square = True)
df


df_


df['income']=df['income'].astype(int)
df['age'] = df['age'].astype(int)
offer_columns = df.columns.to_series().str.contains('^DIS|BOGO')
df.loc[:,offer_columns] = df.loc[:,offer_columns].fillna(0).astype(int)

#df.filter(regex = '^DIS|BOGO',axis = 1).fillna(0, inplace = True)
#df.filter(regex = '^DIS|BOGO',axis = 1).astype(int, inplace = True)
cate_vars = ['gender']
#df.loc[:, ['age', 'income']] = df.loc[:, ['age', 'income']].fillna(value = 0)
df['age'] = df['age'].fillna(value = df['age'].mean())
df['income'] = df['income'].fillna(value = df['income'].mean())

for cate in cate_vars:
    df = pd.concat([df.drop(cate ,axis = 1), pd.get_dummies(df[cate], prefix = cate, prefix_sep = '_', drop_first = True)], axis = 1)




df_back = df.copy()



profit_without_offer_top = df_back['mean_profit_without_offer'].mean() + 3 * df_back['mean_profit_without_offer'].std() 
profit_without_offer_bottom = df_back['mean_profit_without_offer'].mean() - 3 * df_back['mean_profit_without_offer'].std()

profit_diff_top = df_back['profit_diff'].mean() + 3 * df_back['profit_diff'].std() 
profit_diff_bottom = df_back['profit_diff'].mean() - 3 * df_back['profit_diff'].std()

df = df_back[(df_back['mean_profit_without_offer'] < profit_without_offer_top) &
             (df_back['mean_profit_without_offer'] > profit_without_offer_bottom) &
             (df_back['profit_diff'] < profit_diff_top) &
             (df_back['profit_diff'] > profit_diff_bottom) ]

y = df['profit_diff']
x = df.drop(['profit_diff'], axis = 1)
STDS = StandardScaler()
MMS = MinMaxScaler()

std_list = ['age', 'income', 'count_without_offer', 'mean_profit_without_offer']
offer_list = ['BOGO_r10_d10_u5', 'BOGO_r10_d10_u7', 'BOGO_r5_d5_u5', 'BOGO_r5_d5_u7', 'DIS_r2_d10_u10', 'DIS_r2_d10_u7', 'DIS_r3_d7_u7', 'DIS_r5_d20_u10']

for column in std_list:
    x[column] = STDS.fit_transform(x[column].values.reshape(-1,1))

#for column in offer_list:
#    x[column] = MMS.fit_transform(x[column].values.reshape(-1,1))
for column in offer_list:
    x.loc[x[column] >= 1,column] = 1
    
x_train, x_test, y_train, y_test = train_test_split(x, y, random_state =42)


x_train



df_ = trans_profit.drop(['event','offer_used','amount', 'time', 'reward', 'bogo', 'discount', 'reward_cost', 'profit', 'became_member_on', 'person_id'], axis = 1)

#df_ = df_.dropna(subset = ['profit_diff','age', 'income'], axis = 0)
df_ = df_.dropna(subset = ['profit_diff','age', 'income','gender'], axis = 0)

#df_['income_nan'] = df_['income'].isna().astype(int)
#df_['age_nan'] = df_['age'].isna().astype(int)
df_['income'] = df_['income'].astype(int)
df_['age'] = df_['age'].astype(int)

offer_columns = df_.columns.to_series().str.contains('^DIS|BOGO')
df_.loc[:,offer_columns] = df_.loc[:,offer_columns].fillna(0).astype(int)
cate_vars = ['gender']
#df.loc[:, ['age', 'income']] = df.loc[:, ['age', 'income']].fillna(value = 0)

#df_['age'] = df_['age'].fillna(value = df_['age'].mean())
#df_['income'] = df_['income'].fillna(value = df_['income'].mean() )

for cate in cate_vars:
    df_ = pd.concat([df_.drop(cate ,axis = 1), pd.get_dummies(df_[cate], prefix = cate, prefix_sep = '_', drop_first = True)], axis = 1)

    

profit_without_offer_top = df_['mean_profit_without_offer'].mean() + 3 * df_['mean_profit_without_offer'].std() 
profit_without_offer_bottom = df_['mean_profit_without_offer'].mean() - 3 * df_['mean_profit_without_offer'].std()

profit_diff_top = df_['profit_diff'].mean() + 3 * df_['profit_diff'].std() 
profit_diff_bottom = df_['profit_diff'].mean() - 3 * df_['profit_diff'].std()

df_ = df_[(df_['mean_profit_without_offer'] < profit_without_offer_top) &
             (df_['mean_profit_without_offer'] > profit_without_offer_bottom) &
             (df_['profit_diff'] < profit_diff_top) &
             (df_['profit_diff'] > profit_diff_bottom) ]    
y_ = df_['profit_diff']
x_ = df_.drop(['profit_diff'], axis = 1)
STDS = StandardScaler()
RBS = RobustScaler(quantile_range = (15,85))
MMS = MinMaxScaler()

std_list = ['age', 'income']
offer_list = ['BOGO_r10_d10_u5', 'BOGO_r10_d10_u7', 'BOGO_r5_d5_u5', 'BOGO_r5_d5_u7', 'DIS_r2_d10_u10', 'DIS_r2_d10_u7', 'DIS_r3_d7_u7', 'DIS_r5_d20_u10']

for column in std_list:
    x_[column] = STDS.fit_transform(x_[column].values.reshape(-1,1))

for column in offer_list:
    x_[column] = x_[column].fillna(0)
    x.loc[x[column] >= 1,column] = 1
#for column in offer_list:
    
    #x_[column] = MMS.fit_transform(x_[column].values.reshape(-1,1))
x_['mean_profit_without_offer'] = RBS.fit_transform(x_['mean_profit_without_offer'].values.reshape(-1,1))
x_train_, x_test_, y_train_, y_test_ = train_test_split(x_, y_, random_state =42)






x_train.describe()


from sklearn.metrics import classification_report
from sklearn.metrics import matthews_corrcoef
from sklearn.feature_selection import mutual_info_regression
from sklearn.feature_selection import chi2
from sklearn.feature_selection import f_classif

import statsmodels.api as sm


mutual_info_regression(x_train, y_train)


f_classif(x_train,y_train_two)


from sklearn.feature_selection import f_regression
f_reg = pd.DataFrame(f_regression(x_train,y_train), columns = x_train.columns)
f_reg


f_reg = pd.DataFrame(f_regression(x_train_,y_train_), columns = x_train_.columns)
f_reg


X  = sm.add_constant(x_train)
mod = sm.OLS(y_train, X)
res = mod.fit()
print(res.summary())



X  = sm.add_constant(x_train_)
mod = sm.OLS(y_train_, X)
res = mod.fit()
print(res.summary())


model = LinearRegression()
model.fit(x_train,y_train)

print('>>> Train set Score:')
print(model.score(x_train,y_train))
print('>>> Test set Score:')
print(model.score(x_test,y_test))
print(model.coef_)



from sklearn.neural_network import MLPRegressor
model = MLPRegressor(random_state=42,alpha = 1, max_iter=1000)
model.fit(x_train,y_train)

print('>>> Train set Score:')
print(model.score(x_train,y_train))
print('>>> Test set Score:')
print(model.score(x_test, y_test))


model = LinearRegression()
model.fit(x_train_,y_train_)

print('>>> Train set Score:')
print(model.score(x_train_,y_train_))
print('>>> Test set Score:')
print(model.score(x_test_,y_test_))


from sklearn.neural_network import MLPRegressor
model = MLPRegressor(random_state=42,alpha = 0.01, max_iter=5000)
model.fit(x_train_,y_train_)

print('>>> Train set Score:')
print(model.score(x_train_,y_train_))
print('>>> Test set Score:')
print(model.score(x_test_,y_test_))


from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import GridSearchCV

param_grid = {
    'max_depth': [5, 10, 15, 20, None],
    'max_features': ['auto', 'sqrt', 'log2'],
    'min_samples_leaf': [1,2,3,4],
    'min_samples_split': [2,5, 8,10],
    'n_estimators': [ 200, 400, 600, 800]}

RFR = RandomForestRegressor(random_state = 42)
grid_search = GridSearchCV(estimator = RFR, param_grid = param_grid, cv = 3, n_jobs = 4)
grid_search.fit(x_train, y_train)
print(grid_search.best_params_)
# RFR.fit(x_train, y_train)

# print('>>> Train set Score:')
# print(RFR.score(x_train,y_train))
# print('>>> Test set Score:')
# print(RFR.score(x_test,y_test))


from sklearn.ensemble import RandomForestRegressor


RFR = RandomForestRegressor(random_state = 42, n_estimators = 400, max_depth = 5, min_samples_leaf = 2, min_samples_split = 2)
RFR.fit(x_train, y_train)

print('>>> Train set Score:')
print(RFR.score(x_train,y_train))
print('>>> Test set Score:')
print(RFR.score(x_test,y_test))


from sklearn.ensemble import RandomForestRegressor


RFR = RandomForestRegressor(random_state = 42, n_estimators = 400, max_depth = 5, min_samples_leaf = 2, min_samples_split = 2)
RFR.fit(x_train_, y_train_)

print('>>> Train set Score:')
print(RFR.score(x_train_,y_train_))
print('>>> Test set Score:')
print(RFR.score(x_test_,y_test_))


x_train_short = x_train.filter(regex = '^(?!BOGO|DIS)',axis = 1)
x_test_short = x_test.filter(regex = '^(?!BOGO|DIS)',axis = 1)

x_train_short


x_train_short.head()


x_test_short.head()





y.hist(bins = range(-20,20, 1))


from sklearn.multiclass import OneVsRestClassifier
from sklearn.svm import LinearSVC
from sklearn.svm import SVC
from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix
def cate_diff(diff):
    if diff < -5:
        return 'Negative2'
    elif diff < 0:
        return 'Positive1'

    elif diff < 2:
        return 'Positive2'
    else:
        return 'Positive4'
    
#    if diff < 0.5:
#        return 'Negative'
#    else:
#        return 'Positive'
y_train_new_ = y_train_.apply(cate_diff)
y_test_new_ = y_test_.apply(cate_diff)
#MCF = OneVsRestClassifier(LinearSVC(random_state = 42) )
MCF = OneVsRestClassifier(LinearSVC(random_state = 42,
                                    dual = False, 
                                    multi_class = 'crammer_singer' , 
                                    max_iter = 300000, 
                                    class_weight = 'balanced') )

MCF.fit(x_train_, y_train_new_)

y_pred_ = MCF.predict(x_test_)
print(classification_report(y_test_new_,y_pred_, target_names = MCF.classes_))

print(MCF.score(x_test_, y_test_new_))
ConfusionMatrixDisplay.from_estimator( MCF,x_test_, y_test_new_, normalize = 'pred')

#cm = confusion_matrix(y_test_new_, y_pred_, labels = MCF.classes_)
#dist = ConfusionMatrixDisplay(cm, display_labels=MCF.classes_, )
#dist.plot()
#plt.show()




from sklearn.ensemble import RandomForestClassifier
RFC = RandomForestClassifier(n_estimators = 400, random_state = 42, class_weight = 'balanced')

RFC.fit(x_train_, y_train_new_)

y_pred_ = RFC.predict(x_test_)
print(classification_report(y_test_new_,y_pred_, target_names = RFC.classes_))

print(RFC.score(x_test_, y_test_new_))
ConfusionMatrixDisplay.from_estimator( RFC,x_test_, y_test_new_, normalize = 'true')
#cm = confusion_matrix(y_test_new_, y_pred_, labels = RFC.classes_)
#dist = ConfusionMatrixDisplay(cm, display_labels=RFC.classes_, )
#dist.plot()
#plt.show()


x_train_.shape


x_test_.shape


plt.show()





#MCF = OneVsRestClassifier(LinearSVC(random_state = 42) )
MCF = OneVsRestClassifier(LinearSVC(random_state = 42,dual = False, max_iter = 200000, class_weight = 'balanced') )

MCF.fit(x_train, y_train_new)
print(MCF.score(x_test,y_test_new))
y_pred = MCF.predict(x_test)
print(classification_report(y_test_new, y_pred, target_names = MCF.classes_))
ConfusionMatrixDisplay.from_estimator( MCF,x_test, y_test_new, normalize = 'pred')


MCF.classes_


#MCF = OneVsRestClassifier(LinearSVC(random_state = 42,penalty = 'l1', dual = False ,loss = 'hinge', max_iter = 100000, class_weight = 'balanced') )
MCF = OneVsRestClassifier(LinearSVC(random_state = 42,loss = 'hinge', max_iter = 100000, class_weight = 'balanced') )

MCF.fit(x_train, y_train_new)
print(MCF.score(x_test, y_test_new))
y_pred = MCF.predict(x_test)
print(classification_report(y_test_new,y_pred, target_names = MCF.classes_))
ConfusionMatrixDisplay.from_estimator( MCF,x_test, y_test_new, normalize = 'pred')


#MCF = OneVsRestClassifier(LinearSVC(random_state = 42,penalty = 'l1', dual = False ,loss = 'hinge', max_iter = 100000, class_weight = 'balanced') )
MCF = OneVsRestClassifier(LinearSVC(random_state = 42, max_iter = 100000, class_weight = 'balanced') )

MCF.fit(x_train, y_train_new)
y_pred = MCF.predict(x_test)
print(classification_report(y_test_new,y_pred, target_names = MCF.classes_))
ConfusionMatrixDisplay.from_estimator( MCF,x_test, y_test_new, normalize = 'pred')


x_train.drop('count_without_offer', axis = 1, inplace = True)
x_test.drop('count_without_offer', axis = 1, inplace = True)
x_train


def two_cate_diff(diff):
    if diff < 0.4:
        return 'Negative'
    else:
        return 'Positive'
    
y_train_two = y_train.apply(two_cate_diff)
y_test_two = y_test.apply(two_cate_diff)

MCF = OneVsRestClassifier(LinearSVC(random_state = 42,dual = False, max_iter = 100000, class_weight = 'balanced') )

MCF.fit(x_train, y_train_two)
y_pred = MCF.predict(x_test)
print(classification_report(y_test_two,y_pred, target_names = MCF.classes_))
ConfusionMatrixDisplay.from_estimator( MCF,x_test, y_test_two, normalize = 'pred')


def two_cate_diff(diff):
    if diff < 0.5:
        return 'Negative'
    else:
        return 'Positive'
    
y_train_two = y_train.apply(two_cate_diff)
y_test_two = y_test.apply(two_cate_diff)
from sklearn.ensemble import RandomForestClassifier
RFC = RandomForestClassifier(n_estimators = 400, random_state = 42, class_weight = 'balanced')

RFC.fit(x_train, y_train_two)
y_pred = RFC.predict(x_test)
print(classification_report(y_test_two,y_pred, target_names = RFC.classes_))
ConfusionMatrixDisplay.from_estimator(RFC,x_test, y_test_two, normalize = 'pred')


coef = pd.DataFrame(columns = x_train.columns)
coef.loc[0,:] = MCF.coef_[0]
coef


pd.Series(MCF.coef_[0])


#MCF = OneVsRestClassifier(LinearSVC(random_state = 42,penalty = 'l1', dual = False ,loss = 'hinge', max_iter = 100000, class_weight = 'balanced') )
MCF = OneVsRestClassifier(SVC(random_state = 42, max_iter = 100000, class_weight = 'balanced') )

MCF.fit(x_train, y_train_new)
print(MCF.score(x_test, y_test_new))
y_pred = MCF.predict(x_test)
print(classification_report(y_test_new,y_pred, target_names = MCF.classes_))
ConfusionMatrixDisplay.from_estimator( MCF,x_test, y_test_new, normalize = 'true')


def two_cate_diff(diff):
    if diff < 0.5:
        return 'Negative'
    else:
        return 'Positive'
    
y_train_two = y_train.apply(two_cate_diff)
y_test_two = y_test.apply(two_cate_diff)
#MCF = OneVsRestClassifier(LinearSVC(random_state = 42,penalty = 'l1', dual = False ,loss = 'hinge', max_iter = 100000, class_weight = 'balanced') )
MCF = OneVsRestClassifier(SVC(random_state = 42,
                              kernel = 'rbf', 
                              max_iter = 100000, class_weight = 'balanced') )

MCF.fit(x_train, y_train_two)
print(MCF.score(x_test, y_test_two))
y_pred = MCF.predict(x_test)
print('<< Matthews Correlation:')
print(matthews_corrcoef(y_test_two, y_pred))
print(classification_report(y_test_two,y_pred, target_names = MCF.classes_))
ConfusionMatrixDisplay.from_estimator( MCF,x_test, y_test_two, normalize = 'true')


#MCF = OneVsRestClassifier(LinearSVC(random_state = 42,penalty = 'l1', dual = False ,loss = 'hinge', max_iter = 100000, class_weight = 'balanced') )
MCF = OneVsRestClassifier(SVC(random_state = 42,kernel = 'rbf', max_iter = 100000, class_weight = 'balanced') )

MCF.fit(x_train, y_train_new)
print(MCF.score(x_test, y_test_new))
ConfusionMatrixDisplay.from_estimator( MCF,x_test, y_test_new, normalize = 'true')


y_train_two.describe()


def two_cate_diff(diff):
    if diff < 0.5:
        return 'Negative'
    else:
        return 'Positive'
y_train_two = y_train.apply(two_cate_diff)
y_test_two = y_test.apply(two_cate_diff)
from sklearn.neural_network import MLPClassifier
MLP = MLPClassifier(random_state = 42, alpha = 0.05,  max_iter = 5000)
#MLP.fit(x_train, y_train_new)
#print(MLP.score(x_test, y_test_new))
#ConfusionMatrixDisplay.from_estimator( MLP,x_test, y_test_new, normalize = 'true')  
MLP.fit(x_train, y_train_two)
print(MLP.score(x_test, y_test_two))
y_pred = MLP.predict(x_test)
print('<< Matthews Correlation:')
print(matthews_corrcoef(y_test_two, y_pred))
print(classification_report(y_test_two,y_pred, target_names = MLP.classes_))
ConfusionMatrixDisplay.from_estimator( MLP,x_test, y_test_two, normalize = 'pred')  


from sklearn.neural_network import MLPClassifier
MLP = MLPClassifier(alpha=0.01,random_state = 42,max_iter = 500, activation = 'logistic')
MLP.fit(x_train, y_train_new)
print(MLP.score(x_test, y_test_new))
y_pred = MLP.predict(x_test)
print(classification_report(y_test_new,y_pred, target_names = MLP.classes_))
ConfusionMatrixDisplay.from_estimator( MLP,x_test, y_test_new, normalize = 'pred')  


from sklearn.neural_network import MLPClassifier
MLP = MLPClassifier(alpha=0.01,random_state = 42,max_iter = 500)
MLP.fit(x_train, y_train_new)
print(MLP.score(x_test, y_test_new))
y_pred = MLP.predict(x_test)
print(classification_report(y_test_new,y_pred, target_names = MLP.classes_))
ConfusionMatrixDisplay.from_estimator( MLP,x_test, y_test_new, normalize = 'pred')  


from sklearn.neural_network import MLPClassifier

def two_cate_diff(diff):
    if diff <0:
        return 'Negative'
    else:
        return 'Positive'
y_train_two_ = y_train_.apply(two_cate_diff)
y_test_two_ = y_test_.apply(two_cate_diff)
MLP = MLPClassifier(alpha=0.05,random_state = 42,max_iter = 5000)
MLP.fit(x_train_, y_train_two_)
y_pred = MLP.predict(x_test_)
print(classification_report(y_test_two_,y_pred, target_names = MLP.classes_))
print('<< Matthews Correlation:')
print(matthews_corrcoef(y_test_two_, y_pred))
ConfusionMatrixDisplay.from_estimator( MLP,x_test_, y_test_two_, normalize = 'pred') 



fig, ((ax0, ax1), (ax2, ax3)) = plt.subplots(nrows = 2, ncols = 2,figsize  = (12,12))

gender_df = summary_df.loc[:,['gender', 'mean_trans_with_offer','mean_trans_without_offer','count_trans_with_offer','count_trans_without_offer']]
gender_df['gender'].replace('F', 'Female', inplace = True)
gender_df['gender'].replace('M', 'Male', inplace = True)
gender_df['gender'].replace('O', 'Oblivious', inplace = True)




sns.histplot(data = gender_df, x = 'mean_trans_with_offer', hue = 'gender',ax = ax0, stat = 'density', bins = range(0,200,10))
ax0.set_xlabel('Average Price per Customer(with offer)')




sns.histplot(data = gender_df, x = 'mean_trans_without_offer', hue = 'gender',ax = ax1, stat = 'density', bins = range(0,200, 10))

ax1.set_xlabel('Average Price per Customer(without offer)')



sns.histplot(data = gender_df, x = 'count_trans_with_offer', hue = 'gender',ax = ax2)

ax2.set_xlabel('Number of Orders per Customer(with offer)')


sns.histplot(data = gender_df, x = 'count_trans_without_offer', hue = 'gender',ax = ax3, bins = range(0, 40,5))


ax3.set_xlabel('Number of Orders per Customer(without offer)')

plt.show()


offer_trans = clean_trans[clean_trans['event'].isin(['transaction', 'offer completed'])]
offer_trans.head()


offer_count_per_order = offer_trans.groupby(['person_id', 'time'])['offer_id'].count()
sns.histplot(offer_count_per_order, stat = 'density', binwidth = 1)
plt.show()


offer_sum_per_order = offer_trans.groupby(['person_id', 'time']).sum()


offer_sum_per_order_one_offer = offer_sum_per_order.loc[offer_count_per_order==1,:]
offer_sum_per_order_two_offer = offer_sum_per_order.loc[offer_count_per_order==2,:]


offer_sum_per_order_one_offer.head()


offer_sum_one_offer_bogo = offer_sum_per_order_one_offer[offer_sum_per_order_one_offer['offer_id'].isin([1,11,21,31])]
offer_sum_one_offer_discount = offer_sum_per_order_one_offer[offer_sum_per_order_one_offer['offer_id'].isin([101,111,121,131])]
offer_sum_one_offer_bogo.head()


offer_sum_one_offer_bogo = offer_sum_one_offer_bogo.reset_index(level = 'person_id')
offer_sum_one_offer_discount = offer_sum_one_offer_discount.reset_index(level = 'person_id')


offer_mean_one_offer_bogo = offer_sum_one_offer_bogo.groupby('person_id').mean()
offer_mean_one_offer_discount = offer_sum_one_offer_discount.groupby('person_id').mean()


summary_df.head()


one_offer_bogo_df = offer_mean_one_offer_bogo.merge(summary_df[['mean_trans_without_offer', 'gender', 'age', 'income(k)']], left_index = True, right_index = True, how = 'left')
one_offer_discount_df = offer_mean_one_offer_discount.merge(summary_df[['mean_trans_without_offer', 'gender', 'age', 'income(k)']], left_index = True, right_index = True, how = 'left') 


offer_mean_one_offer_bogo_df


one_offer_bogo_df['offer_diff'] = one_offer_bogo_df['amount'] + one_offer_bogo_df['reward'] - one_offer_bogo_df['mean_trans_without_offer']
one_offer_discount_df['offer_diff'] = one_offer_discount_df['amount'] + one_offer_discount_df['reward'] - one_offer_discount_df['mean_trans_without_offer']


np.nan


np.isnan(np.nan)


def my_cate(df, col , by , n = 6):
    """
    create box plot for dataframe , automatic divide dataframe into n part and a NA 
    """

    df_new = df.loc[:,[col, by, 'gender']]

        
    df_new['gender'].replace('M', 'Male', inplace = True)
    df_new['gender'].replace('F', 'Female', inplace = True)
    df_new['gender'].replace('O', 'Oblivious', inplace = True)
    df_new['gender'].fillna('None', inplace = True)
    by_max = df_new[by].max()
    by_min = df_new[by].min()

    by_min_len = len(str(int(round(by_min))))

    if by_min_len > 0:
        by_bottom = math.floor(by_min/(10** (by_min_len - 1))) * 10** (by_min_len - 1)
    else:
        by_bottom = 0
    
    by_step_init = (by_max - by_bottom) / (n )

    by_step = math.ceil(by_step_init) 

    by_border = range(by_bottom, by_bottom + by_step* n+1, by_step)

    labels = []
    labels.append('Na')
    for i in range(0,n):
        labels.append('{}-{}'.format(by_border[i], by_border[i+1]))
    

        
    for index, item in df_new[by].items():
        if np.isnan(item):
            df_new.loc[index, 'by_cate'] = 'Na'
        else:
            i = 0
            while i < n:
                if (item < by_border[i+1]):
                    df_new.loc[index, 'by_cate'] = '{}-{}'.format(by_border[i],by_border[i+1])
                    break
                i += 1 


    return df_new, labels



one_offer_bogo_by_income , income_label = my_cate(one_offer_bogo_df, col = 'offer_diff' , by = 'income(k)' )
one_offer_discount_by_income , income_label = my_cate(one_offer_discount_df, col = 'offer_diff' , by = 'income(k)' )

one_offer_bogo_by_income.rename(columns = {'by_cate':'Income(k) range'}, inplace = True)
one_offer_discount_by_income.rename(columns = {'by_cate':'Income(k) range'}, inplace = True)


one_offer_bogo_by_income.head()


fig, ((ax0, ax1),(ax2, ax3)) = plt.subplots(nrows =2, ncols = 2, figsize = (18,12))

sns.histplot(one_offer_bogo_by_income, x = 'offer_diff' , hue = 'Income(k) range', multiple = 'stack',  bins = range(-50, 50, 5), ax = ax0, hue_order = income_label)
ax0.set_xlabel('Mean of the order(with BOGO) + BOGO reward - Mean of order(without offer)')
ax0.set_title('Histogram of The Order Mean Price Difference with and without BOGO')
ax0.axvline(0, ls = '--')

sns.histplot(one_offer_discount_by_income, x = 'offer_diff' , hue = 'Income(k) range', multiple = 'stack',  bins = range(-50, 50, 5), ax = ax1, hue_order = income_label)
ax1.set_xlabel('Mean of the order(with DISCOUNT) + DISCOUNT reward - Mean of order(without offer)')
ax1.set_title('Histogram of The Order Mean Price Difference with and without DISCOUNT')
ax1.axvline(0, ls = '--')

sns.boxplot(data = one_offer_bogo_by_income, x = 'Income(k) range', y = 'offer_diff', hue = 'gender', ax = ax2, showfliers = False, hue_order = ['None', 'Female', 'Male', 'Oblivious'],order = income_label)
ax2.axhline(0, ls = '--')
ax2.set_xlabel('Income(k)')
ax2.set_ylabel('Mean of the order(with BOGO) + BOGO reward \n - Mean of order(without offer)')
ax2.set_title('Boxplot of The Order Mean Price Difference with and without BOGO')

sns.boxplot(data = one_offer_discount_by_income, x = 'Income(k) range', y = 'offer_diff', hue = 'gender', ax = ax3, showfliers = False,  hue_order = ['None', 'Female', 'Male', 'Oblivious'],order = income_label)
ax3.axhline(0, ls = '--')
ax3.set_xlabel('Income(k)')
ax3.set_ylabel('Mean of the order(with DISCOUNT) + DISCOUNT reward  \n - Mean of order(without offer)')
ax3.set_title('Boxplot of The Order Mean Price Difference with and without DISCOUNT')

plt.show()


bogo_99 = pd.concat([one_offer_bogo_df['mean_trans_without_offer'],one_offer_bogo_df['mean_trans_without_offer']]) .quantile(0.99)
bogo_99


total_99 = pd.concat([one_offer_bogo_df['mean_trans_without_offer'],one_offer_bogo_df['mean_trans_without_offer']]) .quantile(0.99)


one_offer_bogo_99_df = one_offer_bogo_df[one_offer_bogo_df['mean_trans_without_offer'] <= total_99]
one_offer_discount_99_df = one_offer_discount_df[one_offer_discount_df['mean_trans_without_offer'] <= total_99]

one_offer_bogo_by_mean_price , bogo_mean_price_label = my_cate(one_offer_bogo_99_df, col = 'offer_diff' , by = 'mean_trans_without_offer' )
one_offer_discount_by_mean_price , discount_mean_price_label = my_cate(one_offer_discount_99_df, col = 'offer_diff' , by = 'mean_trans_without_offer' )

one_offer_bogo_by_mean_price.head()


one_offer_bogo_by_mean_price.rename(columns = {'by_cate':'Mean Price without offer'}, inplace = True)
one_offer_discount_by_mean_price.rename(columns = {'by_cate':'Mean Price without offer'}, inplace = True)


fig, ((ax0, ax1),(ax2, ax3)) = plt.subplots(nrows =2, ncols = 2, figsize = (18,12))

sns.histplot(one_offer_bogo_by_mean_price, x = 'offer_diff' , hue = 'Mean Price without offer', multiple = 'stack',bins = range(-50, 50, 5),   ax = ax0, hue_order = bogo_mean_price_label)
ax0.set_xlabel('Mean of the order(with BOGO) + BOGO reward - Mean of order(without offer)')
ax0.set_title('Histogram of The Order Mean Price Difference with and without BOGO')
ax0.axvline(0, ls = '--')



sns.histplot(one_offer_discount_by_mean_price, x = 'offer_diff' , hue = 'Mean Price without offer', multiple = 'stack',bins = range(-50, 50, 5), ax = ax1, hue_order = discount_mean_price_label)
ax1.set_xlabel('Mean of the order(with DISCOUNT) + DISCOUNT reward - Mean of order(without offer)')
ax1.set_title('Histogram of The Order Mean Price Difference with and without DISCOUNT')
ax1.axvline(0, ls = '--')

sns.boxplot(data = one_offer_bogo_by_mean_price, x = 'Mean Price without offer', y = 'offer_diff', hue = 'gender', ax = ax2, showfliers = False, hue_order = ['None', 'Female', 'Male', 'Oblivious'],order = bogo_mean_price_label)
ax2.axhline(0, ls = '--')
ax2.set_xlabel('Mean Order Price Without offer')
ax2.set_ylabel('Mean of the order(with BOGO) + BOGO reward \n - Mean of order(without offer)')
ax2.set_title('Boxplot of The Order Mean Price Difference with and without BOGO')

sns.boxplot(data = one_offer_discount_by_mean_price, x = 'Mean Price without offer', y = 'offer_diff', hue = 'gender', ax = ax3, showfliers = False,  hue_order = ['None', 'Female', 'Male', 'Oblivious'],order = discount_mean_price_label)
ax3.axhline(0, ls = '--')
ax3.set_xlabel('Mean Order Price Without offer')
ax3.set_ylabel('Mean of the order(with DISCOUNT) + DISCOUNT reward  \n - Mean of order(without offer)')
ax3.set_title('Boxplot of The Order Mean Price Difference with and without DISCOUNT')

plt.show()


offer_mean_one_offer_bogo_df


offer_mean_one_offer_bogo_mean , income_label = my_cate(offer_mean_one_offer_bogo_df, col = 'offer_diff' , by = 'income(k)' )
offer_mean_one_offer_discount_df , income_label = my_cate(offer_mean_one_offer_discount_df, col = 'offer_diff' , by = 'income(k)' )


total_amount = summary_df.loc[:, ['mean_trans_without_offer','count_trans_without_offer', 'gender', 'income(k)']]
total_amount['total_amt'] = total_amount['mean_trans_without_offer'] * total_amount['count_trans_without_offer']
                                  
fig4 = my_boxplot(total_amount, 'total_amt', 'income(k)', log = False, showfliers = False)
fig4.title('Boxplot for Total Amount By Income')
fig4.xlabel('Income range(k)')
fig4.ylabel('Total Amount')
plt.show()


mean_diff_df = summary_df.loc[:, ['mean_trans_without_offer','mean_trans_with_offer','reward' ,'gender', 'income(k)']]
mean_diff_df['mean_diff'] = mean_diff_df['mean_trans_without_offer']  -  mean_diff_df['mean_trans_with_offer'] 
mean_diff_df['mean_reward_diff'] = mean_diff_df['mean_trans_without_offer']  -  mean_diff_df['mean_trans_with_offer'] - mean_diff_df['reward'] 

mean_diff_df
fig5 = my_boxplot(mean_diff_df, 'mean_reward_diff', 'income(k)', log = False, showfliers = False)
fig5.title('Boxplot for Average price difference with offer By Income')
fig5.xlabel('Income range(k)')
fig5.ylabel('Average Pirce difference')
plt.show()


sns.histplot(mean_diff_df, x = 'mean_diff', bins = range(-100, 100, 5))
plt.show()


sns.histplot(mean_diff_df, x = 'mean_reward_diff', bins = range(-100, 100, 5))
plt.show()


c_c.head()


bogo_df = summary_df.loc[bogo_index,:]
discount_df = summary_df.loc[discount_index,:]


bogo_df.describe()


summary_df.shape


bogo_mean_diff_df = bogo_df.loc[:, ['mean_trans_without_offer','mean_trans_with_offer','reward' ,'gender', 'income(k)']]
bogo_mean_diff_df['mean_diff'] = bogo_mean_diff_df['mean_trans_without_offer']  -  bogo_mean_diff_df['mean_trans_with_offer'] 
bogo_mean_diff_df['mean_reward_diff'] = bogo_mean_diff_df['mean_trans_without_offer']  -  bogo_mean_diff_df['mean_trans_with_offer'] - bogo_mean_diff_df['reward'] 


fig5 = my_boxplot(bogo_mean_diff_df, 'mean_reward_diff', 'income(k)', log = False, showfliers = False)
fig5.title('Boxplot for Average price difference with offer By Income')
fig5.xlabel('Income range(k)')
fig5.ylabel('Average Pirce difference')
plt.show()


clean_trans.head()


trans = clean_trans[clean_trans.duplicated(['time','person_id'], keep = False)]
groupbytrans = trans.groupby(['person_id', 'time'])['offer_id'].count()



trans.groupby(['person_id', 'time']).sum()


trans[trans['person_id'] == 0]


clean_trans.groupby(['person_id', 'time'])


summary_df['income(k)'].hist()
plt.show()
summary_df[['mean_trans_without_offer','gender']].hist(bins = range(0,100, 5))
plt.show()
summary_df['mean_trans_with_offer'].hist(bins = range(0,100, 5))
plt.show()


(summary_df['mean_trans_without_offer'] *summary_df['count_trans_without_offer']).hist(bins = range(0,1000,5))


summary_df['count_trans_without_offer'].hist()


def create_offer_received_completed_matrix(data, profile = profile_new ):
    event_offer_cp = data['event'] == 'offer completed'
    event_offer_re = data['event'] == 'offer received'
    event_offer_vi = data['event'] == 'offer viewed' 
    event_offer_ta = data['event'] == 'offer transaction' 
    
    trans_offer_tag = data[data['event'].isin(['offer completed', 'transaction'])]
    time_duplicated = trans_offer_tag.duplicated(['time', 'person_id'], keep = False)
    
    # all transaction 

    # trans with out offer
    trans_without_offer_df = trans_offer_tag[~ time_duplicated]
    # trans with offer 
    trans_with_offer_df = trans_offer_tag[time_duplicated]

    
    
    # count completed offer
    offer_completed_count = data[event_offer_cp].groupby(['person_id', 'offer_id'])['person_id'].count().unstack(1)

    # offer_completed_count = offer_completed_count.add_suffix('_completed')
    # count received offer
    offer_received_count = data[event_offer_re].groupby(['person_id', 'offer_id'])['person_id'].count().unstack(1)


    #offer_received_count = offer_received_count.add_suffix('_received')    

    #    offer_received_count = data[event_offer_re].groupby(['person_id', 'offer_id'])['person_id'].count().unstack(1)
    # offer_received_count = offer_received_count.add_suffix('_received')    
    reward_ = data[event_offer_cp].groupby(['person_id','time'])['reward'].sum()
    reward_nozero = reward_[reward_!=0]
    mean_reward = reward_nozero.groupby(level = [0]).mean()

    # feature_matrix = offer_completed_count.merge(offer_received_count, on = 'person_id')
    row = offer_received_count.index
    column = offer_received_count.columns
    
    feature_matrix = pd.DataFrame(np.nan, index = row, columns = column)
    for i in row:
        for j in column:
            try:
                if pd.isna(offer_received_count.loc[i,j]):
                    feature_matrix.loc[i,j] = np.nan
                elif pd.isna(offer_completed_count.loc[i,j]):
                    feature_matrix.loc[i,j] = 0
                else:
                    feature_matrix.loc[i,j] = 100 * offer_completed_count.loc[i,j] / offer_received_count.loc[i,j]
            except:
                feature_matrix.loc[i,j] = 0
                continue
    # feature_matrix = offer_completed_count / offer_received_count
    

    
    # get mean amount without offer
    trans_mean_without_offer = trans_without_offer_df.groupby(['person_id'])['amount'].mean()
    trans_mean_without_offer.rename('mean_trans_without_offer', inplace = True)
    # trans_count_without_offer = trans_without_offer_df.groupby(['person_id'])['amount'].count()
    # trans_count_without_offer.rename('count_trans_without_offer')
    # get mean amount with offer
    trans_mean_with_offer = trans_with_offer_df.groupby(['person_id'])['amount'].mean()
    
    trans_mean_with_offer.rename("mean_trans_with_offer", inplace = True)
##    trans_count_with_offer = trans_with_offer_df.groupby(['person_id'])['amount'].count()
##    trans_count_with_offer.rename('count_trans_with_offer')    
    feature_matrix = feature_matrix.merge(trans_mean_without_offer, how = 'left', on = 'person_id')
    feature_matrix = feature_matrix.merge(trans_mean_with_offer, how = 'left', on = 'person_id')
    feature_matrix = feature_matrix.merge(mean_reward,how = 'left', on = 'person_id')
    feature_matrix = feature_matrix.merge(profile_new,how = 'left', on = 'person_id')
    feature_matrix.loc[feature_matrix['gender'] == 'M' , 'gender'] = 100
    feature_matrix.loc[feature_matrix['gender'] == 'F' , 'gender'] = 0
    feature_matrix.loc[feature_matrix['gender'] == 'O' , 'gender'] = 50
    feature_matrix['gender'].fillna(np.nan, inplace = True)
    feature_matrix['gender'].astype(float)
    feature_matrix.drop(['became_member_on', 'person_id'],axis = 1, inplace = True)
    feature_matrix['income'] = feature_matrix['income']/1000
    return feature_matrix
#trans_feature = create_matrix(clean_trans)
trans_df = create_offer_received_completed_matrix(clean_trans)

trans_df.head()


trans_df.describe()


trans_df[trans_df['mean_trans_without_offer']<= 1]


trans_df['mean_trans_without_offer'].hist(bins = range(0, 100, 5))


trans_mat_df = trans_df.drop([2,7],axis = 1)
trans_mat = trans_mat_df.to_numpy()
trans_mat.shape


trans_mat_df_funk = trans_mat_df.drop(
    ['mean_trans_without_offer',
     'mean_trans_with_offer',
     'reward', 'gender','age',
     'income'],
    axis = 1)
trans_mat_funk = trans_mat_df_funk.to_numpy()


trans_mat_df_funk.describe()


def FunkSVD(trans_mat,latent_features=14,learning_rate=0.0001,iters=100):
    '''
    This function performs matrix factorization using a basic form of FunkSVD with no regularization
    
    INPUT:
    ratings_mat - (numpy array) a matrix with users as rows, movies as columns, and ratings as values
    latent_features - (int) the number of latent features used
    learning_rate - (float) the learning rate 
    iters - (int) the number of iterations
    
    OUTPUT:
    user_mat - (numpy array) a user by latent feature matrix
    movie_mat - (numpy array) a latent feature by movie matrix
    '''
    
    # Set up useful values to be used through the rest of the function
    n_users = trans_mat.shape[0] # number of rows in the matrix
    n_feature = trans_mat.shape[1] # number of movies in the matrix
    num_ratings = n_feature*n_users - np.isnan(trans_mat).sum() # total number of ratings in the matrix
    
    # initialize the user and movie matrices with random values
    # helpful link: https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.rand.html
    user_mat = np.random.rand(n_users, latent_features).astype('float64') # user matrix filled with random values of shape user x latent 
    feature_mat = np.random.rand(latent_features, n_feature).astype('float64') # movie matrix filled with random values of shape latent x movies
    print(user_mat.dtype)
    
    # initialize sse at 0 for first iteration
    sse_accum=0
    
    # header for running results
    print("Optimization Statistics")
    print("Iterations | Mean Squared Error ")
    
    # for each iteration
    for i in range(iters):
        # update our sse
        sse_accum = 0.0
        max_error = 0
#        print(sse_accum.dtype)
        # For each user-movie pair
        for row in range(n_users):
            for column in range(n_feature):
                # if the rating exists
                if np.isnan(trans_mat[row,column]) ==False :
                    # compute the error as the actual minus the dot product of the user and movie latent features
                    error_mat = trans_mat[row,column] - np.dot(user_mat[row,:],feature_mat[:,column])
                    # Keep track of the total sum of squared errors for the matrix
                    if abs(error_mat) > max_error:
                        max_error = abs(error_mat)
                    
                    sse_accum += error_mat**2
                    # update the values in each matrix in the direction of the gradient
                    user_mat[row,:] +=  learning_rate*2*error_mat*feature_mat[:,column]
                    feature_mat[:,column] += + learning_rate*2*error_mat*user_mat[row,:]
                    # print results for iteration
        print('SSE for {} iter: {} {}'.format(i+1,max_error, sse_accum))


    return user_mat, feature_mat 


user_mat2, feature_mat2 = FunkSVD(trans_mat,latent_features=30, learning_rate = 0.00005,iters = 100)


trans_mat


pred = np.dot(user_mat,feature_mat)


pred2 = np.dot(user_mat2,feature_mat2)
pred_df2 = pd.DataFrame(pred2, index = trans_mat_df.index, columns = trans_mat_df.columns )
pred_df2.head(10)


trans_mat_df.head(10)


pred_df = pd.DataFrame(pred, index = trans_mat_df_funk.index, columns = trans_mat_df_funk.columns )
pred_df.head()


trans_mat_df_funk.head()


trans_mat_df_funk.apply(pd.unique)



